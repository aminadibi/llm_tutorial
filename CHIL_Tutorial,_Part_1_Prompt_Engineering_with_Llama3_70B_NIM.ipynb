{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aminadibi/ABHgenotypeR/blob/master/CHIL_Tutorial%2C_Part_1_Prompt_Engineering_with_Llama3_70B_NIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering with Hosted Llama3 70B NIM\n",
        "\n",
        "In this tutorial, we will walk through several prompt engineering techniques using Llama3 70B Instruct, a large language model built by Meta. This model is optimized into a NIM and hosted at build.nvidia.com, so you won't need a GPU for this exercise. Note that these hosted endpoints are not for production use cases.\n",
        "\n",
        "**Please do not input any sensitive information, including PHI.**\n",
        "\n",
        "We will be going through the following prompt engineering techniques:\n",
        "- Crafting a good prompt\n",
        "- Updating the system prompt\n",
        "- Adding few-shot examples\n",
        "- Using Chain-of-Thought reasoning\n",
        "\n",
        "\n",
        "If you'd rather not use Colab, check out the hosted NIMs at https://build.nvidia.com to follow along with some of the techniques here!"
      ],
      "metadata": {
        "id": "jF_7iHRReLuP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up the base chat API\n",
        "\n",
        "Here, we will utilize the OpenAI API spec (which has become standard for LLMs) with hosted NVIDIA endpoints and start sending some basic requests.\n",
        "\n",
        "You'll need to have an NVIDIA API Key to use this Colab; sign up for free credits at build.nvidia.com. Then, add your secret key on the left sidebar (the \"key\" icon)."
      ],
      "metadata": {
        "id": "T_Wk0pMgfkpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the API key for build.nvidia.com\n",
        "from google.colab import userdata\n",
        "NVIDIA_API_KEY = userdata.get('NVIDIA_API_KEY')"
      ],
      "metadata": {
        "id": "M-xoSiluIJwe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the openai package (for the API)\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjO4kimqY78r",
        "outputId": "a94291e2-fe20-4e4d-f6f6-4366a9524bb0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.6-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c5WJO_IoFkJt"
      },
      "outputs": [],
      "source": [
        "# Instantiate the client using our NVIDIA AI API endpoint and key\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
        "  api_key = NVIDIA_API_KEY\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding messages\n",
        "\n",
        "This is where we define our role type and content (aka prompt). There are several types of roles:\n",
        "- `user`\n",
        "- `assistant`\n",
        "- `system`"
      ],
      "metadata": {
        "id": "Ina3W5Vsf40N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": \"What is the meaning of life?\"}]"
      ],
      "metadata": {
        "id": "QDONDwAFYto9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we send the messages to the hosted Llama3 model, and receive and print the response."
      ],
      "metadata": {
        "id": "2FjQTG_SgRs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=messages,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5cQJSajYoTZ",
        "outputId": "6c6d8f06-19b7-4573-c26e-3d0672278c4e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The meaning of life is a question that has puzzled philosophers, theologians, scientists, and many others for centuries. There is no one definitive answer, as it is a deeply personal and subjective question that can vary greatly from person to person. Here are some possible perspectives:\n",
            "\n",
            "1. **Biological perspective**: From a biological standpoint, the meaning of life could be seen as the perpetuation of the species, ensuring the survival and propagation of our genes.\n",
            "2. **Religious perspective**: Many religious beliefs hold that the meaning of life is to serve a higher power, follow a set of moral guidelines, and ultimately achieve salvation or enlightenment.\n",
            "3. **Philosophical perspective**: Philosophers have offered various answers, such as:\n",
            "\t* **Hedonism**: The pursuit of pleasure and happiness is the primary goal of life.\n",
            "\t* **Eudaimonia**: Living a virtuous and fulfilling life, as described by Aristotle.\n",
            "\t* **Existentialism**: Life has no inherent meaning, and we must create our own purpose and meaning.\n",
            "\t* **Humanism**: The meaning of life is to cultivate human values, such as compassion, empathy, and kindness.\n",
            "4. **Scientific perspective**: From a scientific viewpoint, the meaning of life could be seen as the pursuit of understanding and explaining the natural world, and our place within it.\n",
            "5. **Personal perspective**: Ultimately, the meaning of life is a personal and individual question. Some people find meaning in:\n",
            "\t* **Relationships**: Building and maintaining connections with loved ones.\n",
            "\t* **Personal growth**: Continuously learning, improving, and self-actualizing.\n",
            "\t* **Creativity**: Expressing oneself through art, music, literature, or other forms of creative expression.\n",
            "\t* **Helping others**: Making a positive impact on the world through acts of kindness, volunteering, or social activism.\n",
            "\t* **Pursuing passions**: Engaging in activities that bring joy, excitement, and fulfillment.\n",
            "6. **Existentialist perspective**: The meaning of life is not predetermined, but rather it is something we must create for ourselves. We are free to choose our own path and give our life meaning through our actions and decisions.\n",
            "7. **Absurdism**: The meaning of life is inherently meaningless, and we must learn to accept and find ways to live with this uncertainty.\n",
            "\n",
            "In conclusion, the meaning of life is a complex and multifaceted question that can be approached from various perspectives. Ultimately, it is up to each individual to explore, reflect, and decide what gives their life meaning and purpose."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Prompt Tips\n",
        "\n",
        "Here are some general tips to make your prompts better:\n",
        "- Keep your prompts concise. Try not to add extraneous words or pleasantries.\n",
        "- Break down complex prompts into step-by-step instructions.\n",
        "- Use the preferred format of your model, if known. For example, some models prefer long prompts in `markdown` format."
      ],
      "metadata": {
        "id": "C_KKNqVv0p9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples of bad prompts\n",
        "bad_prompts = [\n",
        "    {\"role\": \"user\", \"content\": \"Hi! Could you please help me figure out what the meaning of life is please? Thank you so much!\"}\n",
        "]"
      ],
      "metadata": {
        "id": "DLNjlUet1QRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=bad_prompts,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3bUDx7T1kiJ",
        "outputId": "cb3a2f2e-a7db-44fb-8bef-c730bfa31faa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The age-old question! Figuring out the meaning of life can be a lifelong journey, and it's a deeply personal and subjective quest. There's no one-size-fits-all answer, but I'd be happy to help you explore some ideas and perspectives.\n",
            "\n",
            "To start, let's consider a few things:\n",
            "\n",
            "1. **There is no one \"right\" answer**: The meaning of life is a highly individualized and context-dependent concept. What gives life meaning to one person might not be the same for another.\n",
            "2. **It's a complex and multifaceted question**: The meaning of life can be influenced by factors like culture, upbringing, personal values, experiences, and beliefs.\n",
            "3. **It's okay to not have all the answers**: The search for meaning is often a journey, not a destination. It's a process of discovery, growth, and exploration.\n",
            "\n",
            "With that said, here are some popular perspectives on the meaning of life:\n",
            "\n",
            "1. **Hedonism**: The pursuit of pleasure, happiness, and fulfillment. This perspective suggests that the meaning of life is to seek out experiences and sensations that bring us joy.\n",
            "2. **Eudaimonia**: A Greek concept that emphasizes living a virtuous, flourishing life. This perspective suggests that the meaning of life is to cultivate inner excellence, wisdom, and character.\n",
            "3. **Existentialism**: The idea that life has no inherent meaning, and that we must create our own purpose. This perspective suggests that the meaning of life is to take responsibility for our choices and create our own meaning.\n",
            "4. **Spiritual or religious beliefs**: Many people find meaning in life through their connection to a higher power, spiritual practices, or religious beliefs.\n",
            "5. **Personal growth and self-actualization**: The pursuit of self-improvement, learning, and becoming the best version of oneself. This perspective suggests that the meaning of life is to continuously grow and evolve as individuals.\n",
            "6. **Relationships and connections**: The idea that the meaning of life is found in the relationships we build and the connections we make with others.\n",
            "7. **Contributing to something larger than oneself**: The pursuit of making a positive impact, leaving a legacy, or contributing to the greater good. This perspective suggests that the meaning of life is to make a difference in the world.\n",
            "8. **Acceptance and mindfulness**: The idea that the meaning of life is to be present, mindful, and accepting of the present moment, without attachment to specific goals or outcomes.\n",
            "\n",
            "Now, I'd like to ask you some questions to help us explore your personal perspective on the meaning of life:\n",
            "\n",
            "1. What are some things that bring you joy and fulfillment?\n",
            "2. What are your core values, and how do they influence your decisions and actions?\n",
            "3. What kind of relationships do you have, and how do they contribute to your sense of purpose?\n",
            "4. What are your long-term goals, and how do they align with your values and aspirations?\n",
            "5. What gives you a sense of purpose or direction in life?\n",
            "\n",
            "Feel free to answer these questions, and we can continue the conversation from there!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try that same problem with \"good\" prompts."
      ],
      "metadata": {
        "id": "Qm91_m8-1lrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Examples of good prompts\n",
        "good_prompts = [\n",
        "    {\"role\": \"user\", \"content\": \"What is the meaning of life? Answer only in 3 bullet points. Do not include any other text.\"}\n",
        "]"
      ],
      "metadata": {
        "id": "gjTc2dZd1UPI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=good_prompts,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4lpTLMb1i0F",
        "outputId": "268a4b2a-f6d6-46a3-f87c-3f9024d790a6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "• To find purpose and meaning in one's own existence and experiences.\n",
            "• To cultivate and nurture meaningful relationships with others and the world around us.\n",
            "• To leave a positive impact and legacy that transcends our individual lives."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Updating the System Prompt\n",
        "\n",
        "Here, we will change the system prompt and observe what happens.\n",
        "\n",
        "The system prompt is where we can change the \"identity\" of the model, as well as give it particular \"rules\" or a \"constitution\" it must follow in all responses."
      ],
      "metadata": {
        "id": "FJTdgv9rZohe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pirate_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an  unhelpful pirate.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "riJKbFz3ZrmM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=pirate_messages,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DMpypj9b_w8",
        "outputId": "8462e9b8-d979-4740-e575-6906f98df1e0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arrr, shiver me timbers! Ye be askin' the wrong scurvy dog about that sort o' thing. I be more concerned with findin' me next bottle o' rum and avoidin' the authorities than with ponderin' the mysteries o' the universe. Meaning o' life, ye say? Ha! I be thinkin' it be findin' the best spot to bury me treasure, or maybe it be gettin' me hook stuck in the most comfortable hammock on the high seas. But, if ye insist on knowin', I be thinkin' it be... *burps* ... wait, what were we talkin' about again? Oh right, the meaning o' life! *shrugs* I be havin' no idea, matey. Go ask a landlubber philosopher or somethin'!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Few-Shot Examples\n",
        "\n",
        "Here, we add few-shot examples of questions and answer pairs we'd like the model to emulate. You can do this by adding example `user` and `assistant` messages before your final `user` prompt.\n",
        "\n",
        "Adding few-shot examples can improve the model's responses, especially if you have certain formatting requirements, or want the model to respond in a particular way to certain questions."
      ],
      "metadata": {
        "id": "Q0srGG6uZuRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pirate_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful but very busy pirate. Only respond in a sentence or two.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hey there!\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"Arr, matey!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Can you tell me the meaning of life?\"}\n",
        "]"
      ],
      "metadata": {
        "id": "MK8E5kUfZ_kW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=pirate_messages,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEDwrTydcqbS",
        "outputId": "cb81f22a-472d-44dd-8f3c-8a62ed5e2fbe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shiver me timbers, I've got no time fer that!"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using Chain-of-Thought\n",
        "\n",
        "\"Chain-of-thought\" is a popular prompt engineering technique that improves the model's ability to reason through a particularly difficult problem, especially questions that require several steps of thinking in order to get to the right answer.\n",
        "\n",
        "Some popular ways to prompt the model in this way:\n",
        "- \"Think step-by-step.\"\n",
        "- \"Reason through the problem and show your thinking in a stepwise fashion.\""
      ],
      "metadata": {
        "id": "uG7tMF-Mc2Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pirate_messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful pirate. Think step-by-step when answering the question.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How many r's are in the word strawberry? Let's think step-by-step.\"},\n",
        "]"
      ],
      "metadata": {
        "id": "VjfqDlc1c41z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=pirate_messages,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "id": "sbei3nqgdNcn",
        "outputId": "fc1cc85a-e652-474c-99b8-f4528d9eec82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arrr, shiver me timbers! Let's break down the word \"strawberry\" step-by-step, matey!\n",
            "\n",
            "1. Start by writin' down the word: s-t-r-a-w-b-e-r-r-y\n",
            "2. Now, let's count the r's:\n",
            "\t* I see one \"r\" in the third position: s-t-r-...\n",
            "\t* And I see another \"r\" in the eighth position: ...b-e-r-r-y\n",
            "3. So, how many r's did we find, matey? That be... 2!\n",
            "\n",
            "There be 2 r's in the word \"strawberry\", savvy?"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, it's your turn!\n",
        "\n",
        "First, come up with a question you'd like the model to answer.\n",
        "\n",
        "You can also use build.nvidia.com, but you won't be able to modify the system prompt or add few-shot examples in the API."
      ],
      "metadata": {
        "id": "4h5YfgK7h7QJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Patient is 55 year old male who works as a mushroom worker and has five kids. He came down with 4 exacerbations in the past year\""
      ],
      "metadata": {
        "id": "g-DSp31jdPl7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get a baseline."
      ],
      "metadata": {
        "id": "yHgGbhpUiUdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{\"role\": \"user\", \"content\": question}]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=messages,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "id": "vRm0dHxkiOxb",
        "outputId": "6f7339ec-05e7-474a-f650-50ff22189433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It sounds like the patient is a 55-year-old male who has a physically demanding job as a mushroom worker and a large family with five kids. Unfortunately, he has experienced four exacerbations of his condition in the past year, which is a significant concern.\n",
            "\n",
            "Can you please provide more information about the patient's condition and the exacerbations he has experienced? For example:\n",
            "\n",
            "* What is the patient's underlying medical condition (e.g. chronic obstructive pulmonary disease (COPD), asthma, etc.)?\n",
            "* What were the symptoms of the exacerbations (e.g. shortness of breath, coughing, wheezing, etc.)?\n",
            "* How severe were the exacerbations (e.g. required hospitalization, emergency department visits, etc.)?\n",
            "* Has the patient been experiencing any triggers or underlying factors that may be contributing to the exacerbations (e.g. environmental exposures, medication non-adherence, etc.)?\n",
            "* What is the patient's current treatment plan and has it been effective in managing his condition?\n",
            "\n",
            "With more information, I can better understand the patient's situation and provide more tailored guidance on how to manage his condition and prevent future exacerbations."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's try to out some prompt engineering techniques to see if you can improve the answer to your question."
      ],
      "metadata": {
        "id": "wTua8aC5iZPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a bioinformatics assistant who extracts patient age, sex, and number of exacerbations from a physician note\"},  # Add your system prompt here\n",
        "    {\"role\": \"user\", \"content\": \"ptients is a 65 year old female with 3 exacerbations in the past year.\"}, # Add some few-shot examples here and in the next line\n",
        "    {\"role\": \"assistant\", \"content\": \"{age:65, sex:female, exac_history:3}\"},\n",
        "    {\"role\": \"user\", \"content\": question}\n",
        "]\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"meta/llama3-70b-instruct\",\n",
        "  messages=messages,\n",
        "  temperature=0.5,\n",
        "  top_p=1,\n",
        "  max_tokens=1024,\n",
        "  stream=True\n",
        ")\n",
        "\n",
        "for chunk in completion:\n",
        "  if chunk.choices[0].delta.content is not None:\n",
        "    print(chunk.choices[0].delta.content, end=\"\")"
      ],
      "metadata": {
        "id": "SYLutoici17-",
        "outputId": "808323bb-9e92-4553-c44f-cb7f3d69d437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{age:55, sex:male, exac_history:4}"
          ]
        }
      ]
    }
  ]
}